{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f27785ef",
   "metadata": {},
   "source": [
    "Zu Beginn des Projekts wurden die notwendigen Bibliotheken importiert, um eine reibungslose Bearbeitung und Analyse der Daten zu erm√∂glichen. Zum Einsatz kamen pandas und numpy f√ºr die Datenverarbeitung, matplotlib und seaborn f√ºr die grafische Darstellung sowie verschiedene Module aus scikit-learn f√ºr die Modellierung und Auswertung. Gleichzeitig wurde mit einer Einstellung das Anzeigen von Warnmeldungen unterdr√ºckt, um die Lesbarkeit des Outputs zu verbessern. F√ºr die Modellbildung und die Bewertung wurden Funktionen wie train_test_split, LabelEncoder, StandardScaler, RandomForestClassifier sowie verschiedene Metriken wie classification_report, confusion_matrix, roc_auc_score, roc_curve und recall_score eingebunden.\n",
    "\n",
    "Im Anschluss wurde der Datensatz von Invistico Airlines direkt √ºber eine URL eingelesen. Nach dem Laden der Daten erfolgte eine erste Bereinigung, indem alle Zeilen mit fehlenden Werten entfernt wurden. Dies diente dazu, eine m√∂glichst saubere Ausgangsbasis f√ºr die weiteren Analysen und Modellierungen zu schaffen. Nach dem Bereinigungsschritt bestand der Datensatz aus 129.880 Eintr√§gen und umfasste 27 Spalten. Zur besseren √úbersicht wurden die Namen aller enthaltenen Spalten sowie eine Vorschau der ersten Zeilen des Datensatzes angezeigt.\n",
    "\n",
    "Da die Zielvariable \"satisfaction\" urspr√ºnglich als Textwerte vorlag, wurde sie im n√§chsten Schritt in numerische Werte √ºberf√ºhrt. Dabei wurde \"satisfied\" auf 1 und \"dissatisfied\" auf 0 gemappt. Nach der Umwandlung erfolgte eine Kontrolle der Werte, um sicherzustellen, dass nur noch numerische Eintr√§ge vorhanden waren. Anschliessend wurden Zeilen mit fehlenden oder fehlerhaften Angaben in der Zielspalte entfernt, um die Datenqualit√§t weiter zu erh√∂hen. Nach dieser Bereinigung wurde die Zielvariable f√ºr die sp√§tere Modellierung definiert. Zur besseren Einsch√§tzung der Verteilung wurde eine grafische Darstellung erstellt, die zeigte, dass die Klassen \"zufrieden\" und \"unzufrieden\" im Datensatz gut vertreten und relativ ausgewogen waren.\n",
    "\n",
    "F√ºr die Modellierung wurden gezielt sieben relevante Merkmale aus dem Datensatz ausgew√§hlt. Dazu z√§hlten neben demografischen Angaben wie dem Geschlecht und dem Alter auch reisespezifische Informationen wie die Reiseart, die Buchungsklasse, die Flugdistanz sowie Angaben zu Abflug- und Ankunftsversp√§tungen. Um die kategorischen Variablen wie beispielsweise \"Gender\", \"Type of Travel\" und \"Class\" f√ºr das Modell nutzbar zu machen, wurden sie mittels Label-Encoding in numerische Werte umgewandelt. Ausserdem wurden bewusst nur objektive Parameter ber√ºcksichtigt, um sicherzustellen, dass reale und nachvollziehbare Zusammenh√§nge im Vordergrund stehen. Nach dieser Transformation standen s√§mtliche Eingabemerkmale in numerischer Form zur Verf√ºgung, sodass die Daten f√ºr das anschliessende Modelltraining vorbereitet waren. Eine abschliessende Kontrolle best√§tigte, dass alle ausgew√§hlten Features korrekt umgewandelt worden waren und die Datenmatrix die erwartete Form aufwies.\n",
    "\n",
    "Im n√§chsten Schritt wurden die aufbereiteten Daten in Trainings- und Testdaten unterteilt. Dabei wurden 80 Prozent der Datens√§tze f√ºr das Training des Modells verwendet und 20 Prozent f√ºr die sp√§tere Evaluierung zur√ºckgehalten. Insgesamt standen nach der Datenaufbereitung 129.487 Eintr√§ge mit sieben ausgew√§hlten Merkmalen zur Verf√ºgung. Um eine einheitliche Skalierung der numerischen Werte sicherzustellen, wurden die Trainings- und Testdaten anschliessend standardisiert. Dies erm√∂glichte es dem Modell, effizienter zu lernen und vergleichbare Ergebnisse zu liefern. Anstelle eines festen Modells wurde nun ein RandomForestClassifier mit einem Hyperparameter-Tuning (GridSearchCV) eingesetzt. Im Rahmen dieses Tunings wurden verschiedene Kombinationen von Hyperparametern getestet, um das optimale Modell zu finden. Nach dem Training des optimierten Modells auf den Trainingsdaten wurden sowohl die Klassenvorhersagen als auch die vorhergesagten Wahrscheinlichkeiten f√ºr die Testdaten berechnet.\n",
    "\n",
    "Zur √úberpr√ºfung der Vorhersagequalit√§t des Modells wurde eine Confusion Matrix erstellt. Diese Matrix zeigte die tats√§chlichen und die vorhergesagten Klassenzugeh√∂rigkeiten der Testdaten. Das Modell erkannte 8042 unzufriedene Kunden korrekt und ordnete 11879 zufriedene Kunden richtig zu. Auf der anderen Seite wurden 3779 unzufriedene Kunden f√§lschlicherweise als zufrieden klassifiziert, w√§hrend 2198 zufriedene Kunden als unzufrieden eingestuft wurden. Insgesamt ergab sich daraus ein stimmiges Bild, das auf eine solide Vorhersageleistung des Modells hinweist, wobei kleinere Ungenauigkeiten insbesondere bei der Erkennung unzufriedener Kunden auftraten.\n",
    "\n",
    "Erg√§nzend zur Confusion Matrix wurde die Receiver Operating Characteristic (ROC) Curve berechnet und dargestellt. Diese Kurve visualisiert die F√§higkeit des Modells, zwischen zufriedenen und unzufriedenen Kunden zu unterscheiden, indem sie die wahre positive Rate gegen die falsche positive Rate auftr√§gt. Das Modell erreichte dabei eine Area Under the Curve (AUC) von 0.83, was auf eine sehr gute Trennsch√§rfe hinweist. Ein AUC-Wert von 1 w√ºrde eine perfekte Klassifikation bedeuten, w√§hrend ein Wert von 0.5 einer rein zuf√§lligen Zuordnung entsprechen w√ºrde. Die ermittelte AUC von 0.83 zeigt, dass das Modell eine hohe Genauigkeit bei der Unterscheidung der beiden Klassen aufweist.\n",
    "\n",
    "Zus√§tzlich wurde der Recall speziell f√ºr unzufriedene Kunden berechnet, um die F√§higkeit des Modells zur Erkennung dieser wichtigen Gruppe genauer zu bewerten. Der Recall-Wert f√ºr unzufriedene Kunden lag bei 0.68, was bedeutet, dass 68 Prozent aller tats√§chlich unzufriedenen Passagiere vom Modell korrekt identifiziert wurden. Dieser Wert zeigt, dass das Modell eine solide Leistung bei der Erkennung von Unzufriedenheit erzielt, obwohl noch ein gewisser Anteil an unzufriedenen Kunden nicht erkannt wurde. Eine weitere Optimierung des Modells k√∂nnte darauf abzielen, die Erkennungsrate in diesem Bereich noch weiter zu verbessern. Zus√§tzlich wurde die Precision-Recall Curve erstellt, um die Leistung des Modells detaillierter zu untersuchen. Die Kurve zeigt eine hohe Pr√§zision bei niedrigen Recall-Werten und eine deutliche Abnahme der Pr√§zision bei h√∂heren Recall-Werten, was auf eine tendenziell st√§rkere Fokussierung auf die zufriedenen Kunden hinweist.\n",
    "\n",
    "Zur detaillierten Bewertung der Modellg√ºte wurde ein Klassifikationsbericht erstellt, der die wichtigsten Kennzahlen zusammenfasst. Die Precision gibt an, wie zuverl√§ssig die Vorhersagen des Modells sind, also wie viele der als unzufrieden oder zufrieden vorhergesagten Kunden tats√§chlich richtig klassifiziert wurden. F√ºr unzufriedene Kunden betrug die Precision 0.79, was bedeutet, dass 79 Prozent der als unzufrieden eingestuften Passagiere tats√§chlich unzufrieden waren. Die Recall-Rate misst hingegen, wie gut das Modell alle tats√§chlichen F√§lle erkannt hat, also wie viele der unzufriedenen Kunden korrekt gefunden wurden. Hier lag der Recall bei 0.68, was bedeutet, dass 68 Prozent aller unzufriedenen Kunden korrekt erkannt wurden.\n",
    "\n",
    "F√ºr zufriedene Kunden ergab sich eine Precision von 0.76 und ein Recall von 0.84. Daraus ergibt sich der F1-Score, welcher eine harmonische Kombination aus Precision und Recall darstellt und besonders dann eine wichtige Rolle spielt, wenn ein ausgewogenes Verh√§ltnis zwischen beiden Werten angestrebt wird. Der F1-Score lag bei 0.73 f√ºr unzufriedene und 0.80 f√ºr zufriedene Kunden.\n",
    "\n",
    "Zus√§tzlich wurde die Accuracy berechnet, also der Anteil aller korrekten Vorhersagen im Vergleich zur Gesamtzahl der Vorhersagen. Diese betrug 77 Prozent, was bedeutet, dass das Modell insgesamt in 77 Prozent der F√§lle die Kundenzufriedenheit richtig vorhergesagt hat. Auch die berechneten Durchschnittswerte, sowohl der ungewichtete Makro-Durchschnitt als auch der gewichtete Durchschnitt unter Ber√ºcksichtigung der Klassenverteilung, lagen jeweils bei etwa 77 Prozent.\n",
    "\n",
    "Diese Ergebnisse best√§tigen, dass das Modell eine insgesamt solide Leistung bei der Klassifikation von Kundenzufriedenheit erzielt hat, wobei eine leichte Tendenz zur besseren Erkennung zufriedener Kunden zu beobachten war.\n",
    "\n",
    "Abschliessend wurde analysiert, welche Merkmale den gr√∂ssten Einfluss auf die Vorhersage der Kundenzufriedenheit hatten. Dazu wurden die Feature Importances des Random Forest Modells ausgewertet und in einem Balkendiagramm visualisiert. Die Analyse zeigte, dass die Buchungsklasse das wichtigste Merkmal war, gefolgt von Geschlecht und Reiseart. Auch das Alter und die Flugdistanz hatten einen relevanten Einfluss auf die Zufriedenheit. Merkmale wie Abflug- und Ankunftsversp√§tungen spielten hingegen eine untergeordnete Rolle. Diese Ergebnisse geben wertvolle Hinweise darauf, welche Faktoren bei der Gestaltung von Dienstleistungen besonders ber√ºcksichtigt werden sollten, um die Kundenzufriedenheit gezielt zu steigern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b7beca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Sklearn Tools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, recall_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Daten laden\n",
    "url = \"https://raw.githubusercontent.com/DivinitasMaxima/BINA-REPO/refs/heads/main/data/data/Invistico_Airline.csv\"\n",
    "df_Invistico = pd.read_csv(url)\n",
    "df_Invistico.dropna(inplace=True)\n",
    "\n",
    "print(\"Shape:\", df_Invistico.shape)\n",
    "print(\"Spalten:\\n\", df_Invistico.columns.tolist())\n",
    "print(\"\\nüîç Vorschau:\")\n",
    "display(df_Invistico.head())\n",
    "\n",
    "# Vorherige Eintr√§ge anschauen\n",
    "print(\"Vor Verarbeitung:\", df_Invistico['satisfaction'].unique())\n",
    "\n",
    "# Mapping und Typumwandlung\n",
    "df_Invistico['satisfaction'] = df_Invistico['satisfaction'].map({'satisfied': 1, 'dissatisfied': 0})\n",
    "df_Invistico['satisfaction'] = pd.to_numeric(df_Invistico['satisfaction'], errors='coerce')\n",
    "\n",
    "# Nachherige Eintr√§ge anschauen\n",
    "print(\"Nach Mapping:\", df_Invistico['satisfaction'].unique())\n",
    "\n",
    "# Fehlende Bewertungen entfernen\n",
    "df_Invistico = df_Invistico.dropna(subset=['satisfaction'])\n",
    "\n",
    "# Zielvariable definieren\n",
    "target = df_Invistico['satisfaction']\n",
    "\n",
    "# √úbersicht der Verteilung\n",
    "sns.countplot(data=df_Invistico, x='satisfaction')\n",
    "plt.title(\"Verteilung der Zielvariable: Kundenzufriedenheit\")\n",
    "plt.xlabel(\"satisfaction (1 = ja, 0 = nein)\")\n",
    "plt.show()\n",
    "\n",
    "# 2. Feature-Auswahl\n",
    "\n",
    "feature_cols = ['Gender', 'Age', 'Type of Travel', 'Class', 'Flight Distance', \n",
    "                 'Departure Delay in Minutes', 'Arrival Delay in Minutes'] #'Seat comfort',\n",
    "features = df_Invistico[feature_cols].copy()\n",
    "\n",
    "# Kategorische Features labeln\n",
    "for col in features.select_dtypes(include=['object']).columns:\n",
    "    le = LabelEncoder()\n",
    "    features[col] = le.fit_transform(features[col].astype(str))\n",
    "\n",
    "print(\"Input Features:\", features.columns.tolist())\n",
    "print(\"Feature-Matrix Shape:\", features.shape)\n",
    "\n",
    "# 3. Train/Test-Split und Skalierung\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, target, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 4. Modelltraining mit Hyperparameter-Tuning\n",
    "\n",
    "# Parameterbereich definieren\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],        # Anzahl B√§ume\n",
    "    'max_depth': [10, 20, None],             # Maximale Tiefe der B√§ume\n",
    "    'min_samples_split': [2, 5, 10]          # Mindestanzahl Samples f√ºr Split\n",
    "}\n",
    "\n",
    "# GridSearchCV-Objekt erstellen\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(random_state=42),\n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',    # Bewertungsmass\n",
    "    cv=3,                  # 3-fache Cross-Validation\n",
    "    verbose=1,             # Fortschrittsanzeige\n",
    "    n_jobs=-1              # Alle Kerne verwenden\n",
    ")\n",
    "\n",
    "# Hyperparameter-Tuning und Training\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Bestes Modell aus Grid Search holen\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# 5. Vorhersagen und Evaluation mit dem besten Modell\n",
    "\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "y_proba = best_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# 5.1 Confusion Matrix\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n",
    "\n",
    "# 5.2 ROC Curve und AUC\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(fpr, tpr, label='ROC Curve (AUC = {:.2f})'.format(roc_auc_score(y_test, y_proba)))\n",
    "plt.plot([0,1], [0,1], 'k--', alpha=0.6)\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 5.3 Recall f√ºr unzufriedene Kunden\n",
    "\n",
    "recall_unzufrieden = recall_score(y_test, y_pred, pos_label=0)\n",
    "print(f\"Recall (unzufriedene Kunden erkannt): {recall_unzufrieden:.2f}\")\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_proba)\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(recall, precision, marker='.')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 5.4 Weitere Kennzahlen\n",
    "\n",
    "print(\"\\n Klassifikationsbericht:\\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# 6. Feature Importances\n",
    "\n",
    "importances = best_model.feature_importances_\n",
    "feat_df = pd.DataFrame({'Feature': features.columns, 'Importance': importances})\n",
    "feat_df = feat_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot Top Features\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(data=feat_df.head(15), x='Importance', y='Feature', palette='viridis')\n",
    "plt.title(\"Wichtigste Merkmale f√ºr Zufriedenheit\")\n",
    "plt.xlabel(\"Feature Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1c5e14",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Sklearn Tools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, recall_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Daten laden\n",
    "url = \"https://raw.githubusercontent.com/DivinitasMaxima/BINA-REPO/refs/heads/main/data/data/Invistico_Airline.csv\"\n",
    "df_Invistico = pd.read_csv(url)\n",
    "df_Invistico.dropna(inplace=True)\n",
    "\n",
    "print(\"üìä Shape:\", df_Invistico.shape)\n",
    "print(\"üßæ Spalten:\\n\", df_Invistico.columns.tolist())\n",
    "print(\"\\nüîç Vorschau:\")\n",
    "display(df_Invistico.head())\n",
    "\n",
    "# Vorherige Eintr√§ge anschauen\n",
    "print(\"Vor Verarbeitung:\", df_Invistico['satisfaction'].unique())\n",
    "\n",
    "# Mapping und Typumwandlung\n",
    "df_Invistico['satisfaction'] = df_Invistico['satisfaction'].map({'satisfied': 1, 'dissatisfied': 0})\n",
    "df_Invistico['satisfaction'] = pd.to_numeric(df_Invistico['satisfaction'], errors='coerce')\n",
    "\n",
    "# Nachherige Eintr√§ge anschauen\n",
    "print(\"Nach Mapping:\", df_Invistico['satisfaction'].unique())\n",
    "\n",
    "# Fehlende Bewertungen entfernen\n",
    "df_Invistico = df_Invistico.dropna(subset=['satisfaction'])\n",
    "\n",
    "# Zielvariable definieren\n",
    "target = df_Invistico['satisfaction']\n",
    "\n",
    "# √úbersicht der Verteilung\n",
    "sns.countplot(data=df_Invistico, x='satisfaction')\n",
    "plt.title(\"Verteilung der Zielvariable: Kundenzufriedenheit\")\n",
    "plt.xlabel(\"satisfaction (1 = ja, 0 = nein)\")\n",
    "plt.show()\n",
    "\n",
    "# 2. Feature-Auswahl\n",
    "\n",
    "feature_cols = ['Gender', 'Age', 'Type of Travel', 'Class', 'Flight Distance', \n",
    "                'Seat comfort', 'Departure Delay in Minutes', 'Arrival Delay in Minutes']\n",
    "features = df_Invistico[feature_cols].copy()\n",
    "\n",
    "# Kategorische Features labeln\n",
    "for col in features.select_dtypes(include=['object']).columns:\n",
    "    le = LabelEncoder()\n",
    "    features[col] = le.fit_transform(features[col].astype(str))\n",
    "\n",
    "print(\"üß† Input Features:\", features.columns.tolist())\n",
    "print(\"üìä Feature-Matrix Shape:\", features.shape)\n",
    "\n",
    "# 3. Train/Test-Split und Skalierung\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, target, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 4. Modelltraining\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "\n",
    "# 5. Vorhersagen und Evaluation\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "y_proba = model.predict_proba(X_test_scaled)[:, 1]  # Wahrscheinlichkeit f√ºr Klasse 1 (zufrieden)\n",
    "\n",
    "# 5.1 Confusion Matrix\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(\"üßÆ Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n",
    "\n",
    "# 5.2 ROC Curve und AUC\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(fpr, tpr, label='ROC Curve (AUC = {:.2f})'.format(roc_auc_score(y_test, y_proba)))\n",
    "plt.plot([0,1], [0,1], 'k--', alpha=0.6)\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"üéØ ROC Curve\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 5.3 Recall f√ºr unzufriedene Kunden\n",
    "\n",
    "recall_unzufrieden = recall_score(y_test, y_pred, pos_label=0)\n",
    "print(f\"üì¢ Recall (unzufriedene Kunden erkannt): {recall_unzufrieden:.2f}\")\n",
    "\n",
    "# 5.4 Weitere Kennzahlen (optional)\n",
    "\n",
    "print(\"\\nüìã Klassifikationsbericht:\\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# 6. Feature Importances\n",
    "\n",
    "importances = model.feature_importances_\n",
    "feat_df = pd.DataFrame({'Feature': features.columns, 'Importance': importances})\n",
    "feat_df = feat_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot Top Features\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(data=feat_df.head(15), x='Importance', y='Feature', palette='viridis')\n",
    "plt.title(\"üî• Top wichtigste Merkmale f√ºr Zufriedenheit\")\n",
    "plt.xlabel(\"Feature Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
