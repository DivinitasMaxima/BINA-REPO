{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f27785ef",
   "metadata": {},
   "source": [
    "Zu Beginn des Projekts wurden die notwendigen Bibliotheken importiert, um eine reibungslose Bearbeitung und Analyse der Daten zu ermöglichen. Zum Einsatz kamen pandas und numpy für die Datenverarbeitung, matplotlib und seaborn für die grafische Darstellung sowie verschiedene Module aus scikit-learn für die Modellierung und Auswertung. Gleichzeitig wurde mit einer Einstellung das Anzeigen von Warnmeldungen unterdrückt, um die Lesbarkeit des Outputs zu verbessern. Für die Modellbildung und die Bewertung wurden Funktionen wie train_test_split, LabelEncoder, StandardScaler, RandomForestClassifier sowie verschiedene Metriken wie classification_report, confusion_matrix, roc_auc_score, roc_curve und recall_score eingebunden.\n",
    "\n",
    "Im Anschluss wurde der Datensatz von Invistico Airlines direkt über eine URL eingelesen. Nach dem Laden der Daten erfolgte eine erste Bereinigung, indem alle Zeilen mit fehlenden Werten entfernt wurden. Dies diente dazu, eine möglichst saubere Ausgangsbasis für die weiteren Analysen und Modellierungen zu schaffen. Nach dem Bereinigungsschritt bestand der Datensatz aus 129.880 Einträgen und umfasste 27 Spalten. Zur besseren Übersicht wurden die Namen aller enthaltenen Spalten sowie eine Vorschau der ersten Zeilen des Datensatzes angezeigt.\n",
    "\n",
    "Da die Zielvariable \"satisfaction\" ursprünglich als Textwerte vorlag, wurde sie im nächsten Schritt in numerische Werte überführt. Dabei wurde \"satisfied\" auf 1 und \"dissatisfied\" auf 0 gemappt. Nach der Umwandlung erfolgte eine Kontrolle der Werte, um sicherzustellen, dass nur noch numerische Einträge vorhanden waren. Anschliessend wurden Zeilen mit fehlenden oder fehlerhaften Angaben in der Zielspalte entfernt, um die Datenqualität weiter zu erhöhen. Nach dieser Bereinigung wurde die Zielvariable für die spätere Modellierung definiert. Zur besseren Einschätzung der Verteilung wurde eine grafische Darstellung erstellt, die zeigte, dass die Klassen \"zufrieden\" und \"unzufrieden\" im Datensatz gut vertreten und relativ ausgewogen waren.\n",
    "\n",
    "Für die Modellierung wurden gezielt sieben relevante Merkmale aus dem Datensatz ausgewählt. Dazu zählten neben demografischen Angaben wie dem Geschlecht und dem Alter auch reisespezifische Informationen wie die Reiseart, die Buchungsklasse, die Flugdistanz sowie Angaben zu Abflug- und Ankunftsverspätungen. Um die kategorischen Variablen wie beispielsweise \"Gender\", \"Type of Travel\" und \"Class\" für das Modell nutzbar zu machen, wurden sie mittels Label-Encoding in numerische Werte umgewandelt. Ausserdem wurden bewusst nur objektive Parameter berücksichtigt, um sicherzustellen, dass reale und nachvollziehbare Zusammenhänge im Vordergrund stehen. Nach dieser Transformation standen sämtliche Eingabemerkmale in numerischer Form zur Verfügung, sodass die Daten für das anschliessende Modelltraining vorbereitet waren. Eine abschliessende Kontrolle bestätigte, dass alle ausgewählten Features korrekt umgewandelt worden waren und die Datenmatrix die erwartete Form aufwies.\n",
    "\n",
    "Im nächsten Schritt wurden die aufbereiteten Daten in Trainings- und Testdaten unterteilt. Dabei wurden 80 Prozent der Datensätze für das Training des Modells verwendet und 20 Prozent für die spätere Evaluierung zurückgehalten. Insgesamt standen nach der Datenaufbereitung 129.487 Einträge mit sieben ausgewählten Merkmalen zur Verfügung. Um eine einheitliche Skalierung der numerischen Werte sicherzustellen, wurden die Trainings- und Testdaten anschliessend standardisiert. Dies ermöglichte es dem Modell, effizienter zu lernen und vergleichbare Ergebnisse zu liefern. Anstelle eines festen Modells wurde nun ein RandomForestClassifier mit einem Hyperparameter-Tuning (GridSearchCV) eingesetzt. Im Rahmen dieses Tunings wurden verschiedene Kombinationen von Hyperparametern getestet, um das optimale Modell zu finden. Nach dem Training des optimierten Modells auf den Trainingsdaten wurden sowohl die Klassenvorhersagen als auch die vorhergesagten Wahrscheinlichkeiten für die Testdaten berechnet.\n",
    "\n",
    "Zur Überprüfung der Vorhersagequalität des Modells wurde eine Confusion Matrix erstellt. Diese Matrix zeigte die tatsächlichen und die vorhergesagten Klassenzugehörigkeiten der Testdaten. Das Modell erkannte 8042 unzufriedene Kunden korrekt und ordnete 11879 zufriedene Kunden richtig zu. Auf der anderen Seite wurden 3779 unzufriedene Kunden fälschlicherweise als zufrieden klassifiziert, während 2198 zufriedene Kunden als unzufrieden eingestuft wurden. Insgesamt ergab sich daraus ein stimmiges Bild, das auf eine solide Vorhersageleistung des Modells hinweist, wobei kleinere Ungenauigkeiten insbesondere bei der Erkennung unzufriedener Kunden auftraten.\n",
    "\n",
    "Ergänzend zur Confusion Matrix wurde die Receiver Operating Characteristic (ROC) Curve berechnet und dargestellt. Diese Kurve visualisiert die Fähigkeit des Modells, zwischen zufriedenen und unzufriedenen Kunden zu unterscheiden, indem sie die wahre positive Rate gegen die falsche positive Rate aufträgt. Das Modell erreichte dabei eine Area Under the Curve (AUC) von 0.83, was auf eine sehr gute Trennschärfe hinweist. Ein AUC-Wert von 1 würde eine perfekte Klassifikation bedeuten, während ein Wert von 0.5 einer rein zufälligen Zuordnung entsprechen würde. Die ermittelte AUC von 0.83 zeigt, dass das Modell eine hohe Genauigkeit bei der Unterscheidung der beiden Klassen aufweist.\n",
    "\n",
    "Zusätzlich wurde der Recall speziell für unzufriedene Kunden berechnet, um die Fähigkeit des Modells zur Erkennung dieser wichtigen Gruppe genauer zu bewerten. Der Recall-Wert für unzufriedene Kunden lag bei 0.68, was bedeutet, dass 68 Prozent aller tatsächlich unzufriedenen Passagiere vom Modell korrekt identifiziert wurden. Dieser Wert zeigt, dass das Modell eine solide Leistung bei der Erkennung von Unzufriedenheit erzielt, obwohl noch ein gewisser Anteil an unzufriedenen Kunden nicht erkannt wurde. Eine weitere Optimierung des Modells könnte darauf abzielen, die Erkennungsrate in diesem Bereich noch weiter zu verbessern. Zusätzlich wurde die Precision-Recall Curve erstellt, um die Leistung des Modells detaillierter zu untersuchen. Die Kurve zeigt eine hohe Präzision bei niedrigen Recall-Werten und eine deutliche Abnahme der Präzision bei höheren Recall-Werten, was auf eine tendenziell stärkere Fokussierung auf die zufriedenen Kunden hinweist.\n",
    "\n",
    "Zur detaillierten Bewertung der Modellgüte wurde ein Klassifikationsbericht erstellt, der die wichtigsten Kennzahlen zusammenfasst. Die Precision gibt an, wie zuverlässig die Vorhersagen des Modells sind, also wie viele der als unzufrieden oder zufrieden vorhergesagten Kunden tatsächlich richtig klassifiziert wurden. Für unzufriedene Kunden betrug die Precision 0.79, was bedeutet, dass 79 Prozent der als unzufrieden eingestuften Passagiere tatsächlich unzufrieden waren. Die Recall-Rate misst hingegen, wie gut das Modell alle tatsächlichen Fälle erkannt hat, also wie viele der unzufriedenen Kunden korrekt gefunden wurden. Hier lag der Recall bei 0.68, was bedeutet, dass 68 Prozent aller unzufriedenen Kunden korrekt erkannt wurden.\n",
    "\n",
    "Für zufriedene Kunden ergab sich eine Precision von 0.76 und ein Recall von 0.84. Daraus ergibt sich der F1-Score, welcher eine harmonische Kombination aus Precision und Recall darstellt und besonders dann eine wichtige Rolle spielt, wenn ein ausgewogenes Verhältnis zwischen beiden Werten angestrebt wird. Der F1-Score lag bei 0.73 für unzufriedene und 0.80 für zufriedene Kunden.\n",
    "\n",
    "Zusätzlich wurde die Accuracy berechnet, also der Anteil aller korrekten Vorhersagen im Vergleich zur Gesamtzahl der Vorhersagen. Diese betrug 77 Prozent, was bedeutet, dass das Modell insgesamt in 77 Prozent der Fälle die Kundenzufriedenheit richtig vorhergesagt hat. Auch die berechneten Durchschnittswerte, sowohl der ungewichtete Makro-Durchschnitt als auch der gewichtete Durchschnitt unter Berücksichtigung der Klassenverteilung, lagen jeweils bei etwa 77 Prozent.\n",
    "\n",
    "Diese Ergebnisse bestätigen, dass das Modell eine insgesamt solide Leistung bei der Klassifikation von Kundenzufriedenheit erzielt hat, wobei eine leichte Tendenz zur besseren Erkennung zufriedener Kunden zu beobachten war.\n",
    "\n",
    "Abschliessend wurde analysiert, welche Merkmale den grössten Einfluss auf die Vorhersage der Kundenzufriedenheit hatten. Dazu wurden die Feature Importances des Random Forest Modells ausgewertet und in einem Balkendiagramm visualisiert. Die Analyse zeigte, dass die Buchungsklasse das wichtigste Merkmal war, gefolgt von Geschlecht und Reiseart. Auch das Alter und die Flugdistanz hatten einen relevanten Einfluss auf die Zufriedenheit. Merkmale wie Abflug- und Ankunftsverspätungen spielten hingegen eine untergeordnete Rolle. Diese Ergebnisse geben wertvolle Hinweise darauf, welche Faktoren bei der Gestaltung von Dienstleistungen besonders berücksichtigt werden sollten, um die Kundenzufriedenheit gezielt zu steigern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b7beca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Sklearn Tools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, recall_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Daten laden\n",
    "url = \"https://raw.githubusercontent.com/DivinitasMaxima/BINA-REPO/refs/heads/main/data/data/Invistico_Airline.csv\"\n",
    "df_Invistico = pd.read_csv(url)\n",
    "df_Invistico.dropna(inplace=True)\n",
    "\n",
    "print(\"Shape:\", df_Invistico.shape)\n",
    "print(\"Spalten:\\n\", df_Invistico.columns.tolist())\n",
    "print(\"\\n🔍 Vorschau:\")\n",
    "display(df_Invistico.head())\n",
    "\n",
    "# Vorherige Einträge anschauen\n",
    "print(\"Vor Verarbeitung:\", df_Invistico['satisfaction'].unique())\n",
    "\n",
    "# Mapping und Typumwandlung\n",
    "df_Invistico['satisfaction'] = df_Invistico['satisfaction'].map({'satisfied': 1, 'dissatisfied': 0})\n",
    "df_Invistico['satisfaction'] = pd.to_numeric(df_Invistico['satisfaction'], errors='coerce')\n",
    "\n",
    "# Nachherige Einträge anschauen\n",
    "print(\"Nach Mapping:\", df_Invistico['satisfaction'].unique())\n",
    "\n",
    "# Fehlende Bewertungen entfernen\n",
    "df_Invistico = df_Invistico.dropna(subset=['satisfaction'])\n",
    "\n",
    "# Zielvariable definieren\n",
    "target = df_Invistico['satisfaction']\n",
    "\n",
    "# Übersicht der Verteilung\n",
    "sns.countplot(data=df_Invistico, x='satisfaction')\n",
    "plt.title(\"Verteilung der Zielvariable: Kundenzufriedenheit\")\n",
    "plt.xlabel(\"satisfaction (1 = ja, 0 = nein)\")\n",
    "plt.show()\n",
    "\n",
    "# 2. Feature-Auswahl\n",
    "\n",
    "feature_cols = ['Gender', 'Age', 'Type of Travel', 'Class', 'Flight Distance', \n",
    "                 'Departure Delay in Minutes', 'Arrival Delay in Minutes'] #'Seat comfort',\n",
    "features = df_Invistico[feature_cols].copy()\n",
    "\n",
    "# Kategorische Features labeln\n",
    "for col in features.select_dtypes(include=['object']).columns:\n",
    "    le = LabelEncoder()\n",
    "    features[col] = le.fit_transform(features[col].astype(str))\n",
    "\n",
    "print(\"Input Features:\", features.columns.tolist())\n",
    "print(\"Feature-Matrix Shape:\", features.shape)\n",
    "\n",
    "# 3. Train/Test-Split und Skalierung\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, target, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 4. Modelltraining mit Hyperparameter-Tuning\n",
    "\n",
    "# Parameterbereich definieren\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],        # Anzahl Bäume\n",
    "    'max_depth': [10, 20, None],             # Maximale Tiefe der Bäume\n",
    "    'min_samples_split': [2, 5, 10]          # Mindestanzahl Samples für Split\n",
    "}\n",
    "\n",
    "# GridSearchCV-Objekt erstellen\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(random_state=42),\n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',    # Bewertungsmass\n",
    "    cv=3,                  # 3-fache Cross-Validation\n",
    "    verbose=1,             # Fortschrittsanzeige\n",
    "    n_jobs=-1              # Alle Kerne verwenden\n",
    ")\n",
    "\n",
    "# Hyperparameter-Tuning und Training\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Bestes Modell aus Grid Search holen\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# 5. Vorhersagen und Evaluation mit dem besten Modell\n",
    "\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "y_proba = best_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# 5.1 Confusion Matrix\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n",
    "\n",
    "# 5.2 ROC Curve und AUC\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(fpr, tpr, label='ROC Curve (AUC = {:.2f})'.format(roc_auc_score(y_test, y_proba)))\n",
    "plt.plot([0,1], [0,1], 'k--', alpha=0.6)\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 5.3 Recall für unzufriedene Kunden\n",
    "\n",
    "recall_unzufrieden = recall_score(y_test, y_pred, pos_label=0)\n",
    "print(f\"Recall (unzufriedene Kunden erkannt): {recall_unzufrieden:.2f}\")\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_proba)\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(recall, precision, marker='.')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 5.4 Weitere Kennzahlen\n",
    "\n",
    "print(\"\\n Klassifikationsbericht:\\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# 6. Feature Importances\n",
    "\n",
    "importances = best_model.feature_importances_\n",
    "feat_df = pd.DataFrame({'Feature': features.columns, 'Importance': importances})\n",
    "feat_df = feat_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot Top Features\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(data=feat_df.head(15), x='Importance', y='Feature', palette='viridis')\n",
    "plt.title(\"Wichtigste Merkmale für Zufriedenheit\")\n",
    "plt.xlabel(\"Feature Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1c5e14",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Sklearn Tools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, recall_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Daten laden\n",
    "url = \"https://raw.githubusercontent.com/DivinitasMaxima/BINA-REPO/refs/heads/main/data/data/Invistico_Airline.csv\"\n",
    "df_Invistico = pd.read_csv(url)\n",
    "df_Invistico.dropna(inplace=True)\n",
    "\n",
    "print(\"📊 Shape:\", df_Invistico.shape)\n",
    "print(\"🧾 Spalten:\\n\", df_Invistico.columns.tolist())\n",
    "print(\"\\n🔍 Vorschau:\")\n",
    "display(df_Invistico.head())\n",
    "\n",
    "# Vorherige Einträge anschauen\n",
    "print(\"Vor Verarbeitung:\", df_Invistico['satisfaction'].unique())\n",
    "\n",
    "# Mapping und Typumwandlung\n",
    "df_Invistico['satisfaction'] = df_Invistico['satisfaction'].map({'satisfied': 1, 'dissatisfied': 0})\n",
    "df_Invistico['satisfaction'] = pd.to_numeric(df_Invistico['satisfaction'], errors='coerce')\n",
    "\n",
    "# Nachherige Einträge anschauen\n",
    "print(\"Nach Mapping:\", df_Invistico['satisfaction'].unique())\n",
    "\n",
    "# Fehlende Bewertungen entfernen\n",
    "df_Invistico = df_Invistico.dropna(subset=['satisfaction'])\n",
    "\n",
    "# Zielvariable definieren\n",
    "target = df_Invistico['satisfaction']\n",
    "\n",
    "# Übersicht der Verteilung\n",
    "sns.countplot(data=df_Invistico, x='satisfaction')\n",
    "plt.title(\"Verteilung der Zielvariable: Kundenzufriedenheit\")\n",
    "plt.xlabel(\"satisfaction (1 = ja, 0 = nein)\")\n",
    "plt.show()\n",
    "\n",
    "# 2. Feature-Auswahl\n",
    "\n",
    "feature_cols = ['Gender', 'Age', 'Type of Travel', 'Class', 'Flight Distance', \n",
    "                'Seat comfort', 'Departure Delay in Minutes', 'Arrival Delay in Minutes']\n",
    "features = df_Invistico[feature_cols].copy()\n",
    "\n",
    "# Kategorische Features labeln\n",
    "for col in features.select_dtypes(include=['object']).columns:\n",
    "    le = LabelEncoder()\n",
    "    features[col] = le.fit_transform(features[col].astype(str))\n",
    "\n",
    "print(\"🧠 Input Features:\", features.columns.tolist())\n",
    "print(\"📊 Feature-Matrix Shape:\", features.shape)\n",
    "\n",
    "# 3. Train/Test-Split und Skalierung\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, target, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 4. Modelltraining\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "\n",
    "# 5. Vorhersagen und Evaluation\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "y_proba = model.predict_proba(X_test_scaled)[:, 1]  # Wahrscheinlichkeit für Klasse 1 (zufrieden)\n",
    "\n",
    "# 5.1 Confusion Matrix\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(\"🧮 Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n",
    "\n",
    "# 5.2 ROC Curve und AUC\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(fpr, tpr, label='ROC Curve (AUC = {:.2f})'.format(roc_auc_score(y_test, y_proba)))\n",
    "plt.plot([0,1], [0,1], 'k--', alpha=0.6)\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"🎯 ROC Curve\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 5.3 Recall für unzufriedene Kunden\n",
    "\n",
    "recall_unzufrieden = recall_score(y_test, y_pred, pos_label=0)\n",
    "print(f\"📢 Recall (unzufriedene Kunden erkannt): {recall_unzufrieden:.2f}\")\n",
    "\n",
    "# 5.4 Weitere Kennzahlen (optional)\n",
    "\n",
    "print(\"\\n📋 Klassifikationsbericht:\\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# 6. Feature Importances\n",
    "\n",
    "importances = model.feature_importances_\n",
    "feat_df = pd.DataFrame({'Feature': features.columns, 'Importance': importances})\n",
    "feat_df = feat_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot Top Features\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(data=feat_df.head(15), x='Importance', y='Feature', palette='viridis')\n",
    "plt.title(\"🔥 Top wichtigste Merkmale für Zufriedenheit\")\n",
    "plt.xlabel(\"Feature Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
