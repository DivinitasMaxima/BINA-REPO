{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9x7FY8icHpt"
      },
      "source": [
        "# Management Summary\n",
        "\n",
        "# 1. Einleitung\n",
        "\n",
        "Die Kundenzufriedenheit spielt eine zentrale Rolle in der wettbewerbsintensiven Luftfahrtbranche. Fluggäste erwarten nicht nur eine sichere und pünktliche Beförderung, sondern auch einen exzellenten Service, der ihr Reiseerlebnis positiv beeinflusst. Gerade auf Flugreisen ist die Kundschaft besonders sensibel für die Qualität des angebotenen Services, sei es aufgrund der hohen Ticketpreise oder der unterbewussten Anspannung während des Flugs. Kleine Details im Service können sich summieren und erheblichen Einfluss auf die Wahrnehmung und Zufriedenheit der Passagiere haben. (International, 2014).\n",
        "\n",
        "Um das Kundenerlebnis systematisch zu optimieren, setzt American Airlines auf Bernard Marrs fünfstufigen Ansatz zur datengetriebenen Entscheidungsfindung. Dieser methodische Ansatz ermöglicht es, fundierte Entscheidungen zu treffen und gezielte Massnahmen zur Verbesserung der Kundenzufriedenheit zu ergreifen. Die vorliegende Arbeit untersucht diesen Prozess detailliert und konzentriert sich dabei auf die ersten vier der fünf Schritte von Marrs (2020):\n",
        "\n",
        "1.  Ziel und Informationsbedarf definieren (Kapitel 2): Hier werden die Hauptziele festgelegt, die als Grundlage für die weiteren Analysen dienen.\n",
        "2.  Daten sammeln (Kapitel 3): Dieser Abschnitt behandelt die verschiedenen Aspekte der Datenerhebung, darunter Datenquellen, Datenqualität, Datenbereinigung und Datenmodellierung.\n",
        "3.  Daten analysieren (Kapitel 4): Die gesammelten und aufbereiteten Daten werden analysiert, um fundierte Erkenntnisse zu gewinnen.\n",
        "4.  Informationen präsentieren (Kapitel 6): Die Analyseergebnisse werden strukturiert aufbereitet und visualisiert, um eine fundierte Entscheidungsgrundlage zu schaffen.\n",
        "\n",
        "Der fünfte Schritt, datengestützte Entscheidungen treffen, wird in dieser Arbeit nicht umgesetzt, da er nicht Teil der Aufgabenstellung ist.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Ziel und Informationsbedarf definieren\n",
        "\n",
        "American Airlines verfolgt das Ziel, die Kundenzufriedenheit kontinuierlich zu verbessern, um sich im hart umkämpften Luftverkehrsmarkt erfolgreich zu behaupten. Dazu ist es notwendig, die wesentlichen Einflussfaktoren zu identifizieren, die das Reiseerlebnis der Passagiere positiv oder negativ beeinflussen. Ein datenbasierter Ansatz ermöglicht es, fundierte Entscheidungen zur Optimierung des Services und der betrieblichen Abläufe zu treffen.\n",
        "\n",
        "Im Rahmen dieser Projektarbeit sollen daher folgende zentrale Fragen untersucht werden:\n",
        "\n",
        "1.  Welche Faktoren haben den grössten Einfluss auf die Kundenzufriedenheit im Luftverkehr?\n",
        "2.  Welche Faktoren beeinflussen Flugverspätungen am meisten?\n",
        "3.  Wie variieren Passagieraufkommen und Flugverkehr über Zeit und Regionen hinweg, und welche Auswirkungen hat dies auf die Kundenzufriedenheit?"
      ],
      "metadata": {
        "id": "y9B_8mbZKWDu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Daten sammeln\n",
        "Eine systematische und strukturierte Datensammlung ist der Grundstein für die spätere Analyse und Entscheidungsfindung. Im folgenden Kapitel werden die verschiedenen Aspekte des Datenbeschaffungsprozesses behandelt.\n",
        "\n",
        "## 3.1 Datenquellen\n",
        "Die Fluggesellschaft möchte die Faktoren verstehen, die die Kundenzufriedenheit beeinflussen, und Strategien identifizieren, um das Kundenerlebnis zu verbessern. Leider gibt American Airlines keine konkreten Zahlen zu Kundenumfragen oder anderen relevanten Statistiken heraus. Aus diesem Grund bedient sich die Projektgruppe öffentlich zugänglicher, anonymisierter Daten von Kaggle, einer Plattform, die über 50.000 Datensätze zu verschiedensten Themen bietet (Kaggle, o. J.). Die Projektgruppe nutzt diese anonymisierten Datensätze gezielt und wendet sie auf American Airlines an, um daraus relevante Erkenntnisse abzuleiten.\n",
        "\n",
        "Die Projektgruppe arbeitet mit den folgenden Datenquellen:\n",
        "\n",
        "- Kundenzufriedenheitsumfrage XX (Annahme, dass diese Umfrage von American Airlines durchgeführt wurde) QUELLE\n",
        "- Flugverspätungen: https://www.kaggle.com/datasets/ulrikthygepedersen/airlines-delay/code\n",
        "- Grösste Flughäfen nach Passagieraufkommen zwischen 2016 und 2020: https://www.kaggle.com/datasets/khaiid/most-crowded-airports\n",
        "- XX (weitere relevante Datensätze, die später spezifiziert werden) QUELLE\n",
        "\n",
        "## 3.2 Datenqualität und -bereinigung\n",
        "\n",
        "**Kundenzufriedenheitsumfrage**\n",
        "\n",
        "Für diesen Datensatz wurde zunächst überprüft ob sich leere Felder im Datensatz befinden, welche in diesem Fall entfernt worden währen. Daraufhin wurden die Werte in verschiedenen Spalten umgewnadelt damit leichter mit ihnen zu arbeiten war. So wurden unteranderem die Werte in der Zielspalte \"Satisfaction“ in binäre Werte umgewandelt, 1 für \"satisfied\" und 0 für dissatisfied\". Aber auch andere Spalten wie zum Beispiel die Spalten \"Gender\", \"Customer Type\", \"Type of Travel\" und \"Class\" wurden zum besseren arbeiten mit den Daten in numerische Werte umgewandelt.\n",
        "\n",
        "xx\n",
        "\n",
        "\n",
        "x\n",
        "\n",
        "**Flugverspätungen**\n",
        "\n",
        "Für eine zielgerichtete Analyse der Flugverspätungen wurde zunächst der Datensatz \"Airlines Delay\" von Kaggle geladen. Die Daten enthalten Informationen zu verschiedenen Fluggesellschaften und deren Verbindungen. Zur Fokussierung auf eine homogene Datenbasis wurden ausschliesslich Flüge der Fluggesellschaft American Airlines (AA) berücksichtigt. Alle anderen Einträge wurden aus dem Datensatz entfernt, um Verzerrungen durch unterschiedliche Betriebsmodelle der Airlines zu vermeiden.\n"
      ],
      "metadata": {
        "id": "gCW9DRn8Khq-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Datensatz \"Airlines Delay\" von Kaggle herunterladen\n",
        "import kagglehub\n",
        "from kagglehub import KaggleDatasetAdapter\n",
        "\n",
        "file_path = \"airlines_delay.csv\"\n",
        "\n",
        "# Die letzte Version des Datensatzes laden\n",
        "df_airlines_delay = kagglehub.load_dataset(\n",
        "  KaggleDatasetAdapter.PANDAS,\n",
        "  \"ulrikthygepedersen/airlines-delay\",\n",
        "  file_path,\n",
        ")\n",
        "\n",
        "print(\"First 5 records:\", df_airlines_delay.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIp79YjOK0FO",
        "outputId": "1a94f02d-d5e0-4995-9360-e828ceaa7c95"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b50ad5141833>:8: DeprecationWarning: load_dataset is deprecated and will be removed in future version.\n",
            "  df_airlines_delay = kagglehub.load_dataset(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/ulrikthygepedersen/airlines-delay?dataset_version_number=1&file_name=airlines_delay.csv...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5.85M/5.85M [00:00<00:00, 66.0MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting zip of airlines_delay.csv...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 records:    Flight    Time  Length Airline AirportFrom AirportTo  DayOfWeek  Class\n",
            "0  2313.0  1296.0   141.0      DL         ATL       HOU          1      0\n",
            "1  6948.0   360.0   146.0      OO         COS       ORD          4      0\n",
            "2  1247.0  1170.0   143.0      B6         BOS       CLT          3      0\n",
            "3    31.0  1410.0   344.0      US         OGG       PHX          6      0\n",
            "4   563.0   692.0    98.0      FL         BMI       ATL          4      0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Im nächsten Schritt wurde die Qualität der Daten überprüft. Dabei zeigte sich, dass keine fehlenden Werte vorhanden waren, was auf eine hohe Vollständigkeit der Daten hinweist. Um Redundanzen zu vermeiden, wurden zusätzlich doppelte Einträge identifiziert und gelöscht – insgesamt über 216.000 Duplikate."
      ],
      "metadata": {
        "id": "WMs_w-p1Nsdl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fehlende Werte analysieren\n",
        "print(df_airlines_delay.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOr9RaXQLkWu",
        "outputId": "8877bcda-714a-4e8a-96aa-9e092c7551de"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flight         0\n",
            "Time           0\n",
            "Length         0\n",
            "Airline        0\n",
            "AirportFrom    0\n",
            "AirportTo      0\n",
            "DayOfWeek      0\n",
            "Class          0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Suche nach doppelten Zeilen und lösche diese\n",
        "print(df_airlines_delay.duplicated().sum())\n",
        "df_airlines_delay.drop_duplicates(inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C14PtyOyMCM5",
        "outputId": "0b31d79b-1ec0-4d22-8d9f-30b662c2d5d6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "216618\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ein Blick auf die Datentypen der einzelnen Spalten stellte sicher, dass alle Informationen korrekt formatiert waren, etwa Zahlenwerte als numerische Typen und Flughafencodes als Zeichenketten."
      ],
      "metadata": {
        "id": "M4hKR4aAN2Ol"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Zeige die Datentypen aller Spalten an\n",
        "print(df_airlines_delay.dtypes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNkj5MDLMHox",
        "outputId": "6dd3bc4f-c985-4de3-a65c-c966815a390e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flight         float64\n",
            "Time           float64\n",
            "Length         float64\n",
            "Airline         object\n",
            "AirportFrom     object\n",
            "AirportTo       object\n",
            "DayOfWeek        int64\n",
            "Class            int64\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lösche alle Zeilen, die nicht AA in Airline haben\n",
        "\n",
        "df_airlines_delay = df_airlines_delay[df_airlines_delay['Airline'] == 'AA']\n",
        "df_airlines_delay['Airline'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jH-NCNmMHa-",
        "outputId": "546274d2-8a38-497f-9f29-475e032984b0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['AA'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Zur Ergänzung der Daten wurde ein zweiter Datensatz mit den passagierstärksten Flughäfen weltweit (Zeitraum 2016–2020) integriert. Dieser enthielt unter anderem die IATA-Codes sowie die Anzahl der Passagiere pro Flughafen und Jahr. Über eine Extraktion der IATA-Codes aus dem kombinierten Spaltenfeld `Code`\n",
        "\\konnten diese mit den Abflug- und Ankunftsorten (`AirportFrom`, `AirportTo`) der American-Airlines-Flüge verknüpft werden."
      ],
      "metadata": {
        "id": "7nXbtLH_OH_8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Datensatz \"Most Crowded Airports\" von Kaggle herunterladen\n",
        "!pip install kagglehub[pandas-datasets]\n",
        "import kagglehub\n",
        "from kagglehub import KaggleDatasetAdapter\n",
        "\n",
        "# The 'file_path' should contain the actual filename and extension.\n",
        "file_path = \"airports.csv\"  # Replace 'airports.csv' with the actual filename if different.\n",
        "\n",
        "# Load the latest version\n",
        "df_crowded_airports = kagglehub.load_dataset(\n",
        "    KaggleDatasetAdapter.PANDAS,\n",
        "    \"khaiid/most-crowded-airports\",\n",
        "    file_path,\n",
        ")\n",
        "\n",
        "print(\"First 5 records:\", df_crowded_airports.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPUo_DBlMQaY",
        "outputId": "3c31a5b6-8242-4bec-8e8e-9aecd2f26c0a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kagglehub[pandas-datasets] in /usr/local/lib/python3.11/dist-packages (0.3.11)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from kagglehub[pandas-datasets]) (24.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from kagglehub[pandas-datasets]) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kagglehub[pandas-datasets]) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kagglehub[pandas-datasets]) (4.67.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from kagglehub[pandas-datasets]) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas->kagglehub[pandas-datasets]) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->kagglehub[pandas-datasets]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->kagglehub[pandas-datasets]) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->kagglehub[pandas-datasets]) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub[pandas-datasets]) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub[pandas-datasets]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub[pandas-datasets]) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub[pandas-datasets]) (2025.1.31)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->kagglehub[pandas-datasets]) (1.17.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-f50268a1e3b6>:10: DeprecationWarning: load_dataset is deprecated and will be removed in future version.\n",
            "  df_crowded_airports = kagglehub.load_dataset(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/khaiid/most-crowded-airports?dataset_version_number=1&file_name=airports.csv...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.1k/26.1k [00:00<00:00, 25.0MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 records:    Rank                                            Airport  \\\n",
            "0     1       China Guangzhou Baiyun International Airport   \n",
            "1     2  United States Hartsfield–Jackson Atlanta Inter...   \n",
            "2     3      China Chengdu Shuangliu International Airport   \n",
            "3     4  United States Dallas/Fort Worth International ...   \n",
            "4     5        China Shenzhen Bao'an International Airport   \n",
            "\n",
            "                             Location        Country      Code  Passengers  \\\n",
            "0  Baiyun-Huadu, Guangzhou, Guangdong          China  CAN/ZGGG    43760427   \n",
            "1                    Atlanta, Georgia  United States  ATL/KATL    42918685   \n",
            "2   Shuangliu-Wuhou, Chengdu, Sichuan          China  CTU/ZUUU    40741509   \n",
            "3            Dallas-Fort Worth, Texas  United States  DFW/KDFW    39364990   \n",
            "4         Bao'an, Shenzhen, Guangdong          China  SZX/ZGSZ    37916059   \n",
            "\n",
            "   Year  \n",
            "0  2020  \n",
            "1  2020  \n",
            "2  2020  \n",
            "3  2020  \n",
            "4  2020  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_crowded_airports[['IATA', 'ICAO']] = df_crowded_airports['Code'].str.split('/', n=1, expand=True)\n",
        "\n",
        "print(df_crowded_airports.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYlQhjVnMcgM",
        "outputId": "2082dfa4-1c09-47fc-edca-aafcf5db3c7a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Rank                                            Airport  \\\n",
            "0     1       China Guangzhou Baiyun International Airport   \n",
            "1     2  United States Hartsfield–Jackson Atlanta Inter...   \n",
            "2     3      China Chengdu Shuangliu International Airport   \n",
            "3     4  United States Dallas/Fort Worth International ...   \n",
            "4     5        China Shenzhen Bao'an International Airport   \n",
            "\n",
            "                             Location        Country      Code  Passengers  \\\n",
            "0  Baiyun-Huadu, Guangzhou, Guangdong          China  CAN/ZGGG    43760427   \n",
            "1                    Atlanta, Georgia  United States  ATL/KATL    42918685   \n",
            "2   Shuangliu-Wuhou, Chengdu, Sichuan          China  CTU/ZUUU    40741509   \n",
            "3            Dallas-Fort Worth, Texas  United States  DFW/KDFW    39364990   \n",
            "4         Bao'an, Shenzhen, Guangdong          China  SZX/ZGSZ    37916059   \n",
            "\n",
            "   Year IATA  ICAO  \n",
            "0  2020  CAN  ZGGG  \n",
            "1  2020  ATL  KATL  \n",
            "2  2020  CTU  ZUUU  \n",
            "3  2020  DFW  KDFW  \n",
            "4  2020  SZX  ZGSZ  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Im Zuge der Verknüpfung wurden zwei neue Spalten ergänzt:\n",
        "\n",
        "*   `AirportFromCrowd`: Passagieraufkommen am Abflughafen\n",
        "*   `AirportToCrowd`: Passagieraufkommen am Ankunftsflughafen\n",
        "\n",
        "So lässt sich künftig analysieren, ob ein Zusammenhang zwischen dem Verkehrsaufkommen eines Flughafens und der Wahrscheinlichkeit für Verspätungen besteht."
      ],
      "metadata": {
        "id": "Z1IZx5P3OkGL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# Merge Passenger für 'AirportFrom'\n",
        "merged_df_from = pd.merge(df_airlines_delay, df_crowded_airports[['IATA', 'Passengers']], left_on='AirportFrom', right_on='IATA', how='left')\n",
        "df_airlines_delay['AirportFromCrowd'] = merged_df_from['Passengers']\n",
        "\n",
        "# Merge Passenger für 'AirportTo'\n",
        "merged_df_to = pd.merge(df_airlines_delay, df_crowded_airports[['IATA', 'Passengers']], left_on='AirportTo', right_on='IATA', how='left')\n",
        "df_airlines_delay['AirportToCrowd'] = merged_df_to['Passengers']\n",
        "\n",
        "print(\"First 5 records:\", df_airlines_delay.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxcEfLHDMi7M",
        "outputId": "b21d0048-3efb-4bd7-c7a5-835d0a1d584c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 records:     Flight    Time  Length Airline AirportFrom AirportTo  DayOfWeek  Class  \\\n",
            "7   1300.0  1210.0    80.0      AA         DFW       MEM          3      0   \n",
            "89   550.0  1030.0   150.0      AA         LAS       DFW          7      0   \n",
            "92  1827.0  1030.0   225.0      AA         DFW       SMF          1      0   \n",
            "94   655.0   540.0   250.0      AA         JFK       STT          6      0   \n",
            "99  1822.0   875.0   130.0      AA         DFW       DAY          7      0   \n",
            "\n",
            "    AirportFromCrowd  AirportToCrowd  \n",
            "7         48566803.0             NaN  \n",
            "89        61623756.0             NaN  \n",
            "92               NaN      69112607.0  \n",
            "94               NaN      65670697.0  \n",
            "99        53099282.0      58813103.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Abschliessend wurde noch überprüft, wie viele unterschiedliche Werte in den Spalten vorhanden sind. Dabei wurde sichtbar, dass nicht für alle Flughäfen Informationen zum Passagieraufkommen vorliegen. Diese Lücken können auf Flughäfen zurückzuführen sein, die nicht zu den grössten weltweit zählen oder im Zeitraum der Erhebung nicht erfasst wurden. Ein möglicher Umgang damit wäre entweder die Imputation fehlender Werte, das Einholen zusätzlicher Daten oder die gezielte Einschränkung der Analyse auf vollständig verknüpfte Datensätze."
      ],
      "metadata": {
        "id": "KEri04-DO--Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Berechne die Anzahl der eindeutigen Werte pro Spalte\n",
        "unique_counts = df_airlines_delay.nunique()\n",
        "\n",
        "print(unique_counts)\n",
        "\n",
        "#ACHTUNG HIER FEHLEN VIELE FLUGHAFEN - wie sollen wir das machen?"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjvBcq1VM1dM",
        "outputId": "17bbcdc2-3b24-4e33-9b98-ae4c46232417"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flight              1281\n",
            "Time                 229\n",
            "Length                98\n",
            "Airline                1\n",
            "AirportFrom           78\n",
            "AirportTo             78\n",
            "DayOfWeek              7\n",
            "Class                  2\n",
            "AirportFromCrowd      75\n",
            "AirportToCrowd        76\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.4 Datenmodellierung"
      ],
      "metadata": {
        "id": "xVZirmABK-bN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4 Daten analysieren\n",
        "Im Zentrum der Datenanalyse stehen \"Descriptive\", \"Diagnostic\" und \"Predictive Analytics\" im Vordergrund.\n",
        "Die beschreibende Analyse bezieht sich hauptsächlich die Analyse historischer Daten, um vergangene Ereignisse zu verstehen. Ziel ist es Muster und Trends in den Daten zu identifizieren. Übliche Methoden sind Mittelwerte, Standardabweichungen, minimale und maximale Werte, Korrelationen und Kreuztabellen. Für die Visualisierung werden Dashboards und Diagramme oder sogenannte Heatmaps erstellt. Mit \"Diagnostic Analytics\" wird einen Schritt weiter gegangen und versucht die Ursachen für bestimmte Ereignisse oder Trends zu identifizieren. Hierbei werden zusätzliche Techniken wie sogenannte \"Drill-Down-Analysen\", Korrelationen und Hypothesentests durchgeführt.\n",
        "\"Predictive Analytics\" nutzt historische Daten und statistische Modelle, um zukünftige Ereignisse vorherzusagen. Dabei werden Instrumente wie maschinelles Lernen, Regressionsmodelle und Zeitreihenanalysen durchgeführt (Rashedi, 2024).\n",
        "\n",
        "## 4.1 Untergeordneten Fragestellungen inkl. Code\n",
        "\n",
        "Fragestellung: Gibt es bestimmte Wochentage oder Tageszeiten mit besonders vielen Verspätungen? Sind Wochenendflüge pünktlicher als Flüge unter der Woche?\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zLSeq6UDKyp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Literaturverzeichnis\n",
        "Interanational, B. (2014, Dezember 11). *Airline Customer Experience*. B2B International. https://www.b2binternational.de/airline-customer-experience-ein-lacheln-kostet-nichts/)\n",
        "\n",
        "Kaggle. (o. J.). Kaggle: Your Machine Learning and Data Science Community. Abgerufen am 31. März 2024, von https://www.kaggle.com/\n",
        "\n",
        "Marr, B. (2020). From data to decisions: A five-step approach to data-driven decision-making. CPA Management Accounting Guideline.\n",
        "\n",
        "Rashedi, J. (2024). Customer Analytics. In J. Rashedi, Customer Insights (S. 65–97). Springer Fachmedien Wiesbaden. https://doi.org/10.1007/978-3-658-43392-5_5\n"
      ],
      "metadata": {
        "id": "96MrtvoLK4cV"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}